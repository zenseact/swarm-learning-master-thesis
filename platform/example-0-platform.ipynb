{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The basics of the ML platform\n",
    "This ML platform is a highly capable and customisable tool for building and training machine learning models. It takes a configuration object with various parameters, such as data location, image size, model type, and loss function, to simplify the process of building and training models. The platform can be used for central and decentralized training and allows access to data without running any training. The platform makes it easy to build and train machine learning models with minimal coding and configuration.\n",
    "\n",
    "In this notebook we will go through the basics of the platform. We will start by importing the platform and creating a configuration object. We will then use the configuration object to create a dataset and a model. We will then train the model and evaluate the results."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## About the platform\n",
    "The platform is developed to allow for fast iteration and development of benchmarks and tests between different learning methods. Currently, the platform supports the methods:\n",
    "\n",
    "- Centralised learning\n",
    "- Federated learning (uses Flower)\n",
    "- Swarm learning (uses ray)\n",
    "- Federated baseline (edgeless graph case of swarm)\n",
    "\n",
    "### Tutorial notebooks\n",
    "There are not many and there is not really to much planned in terms of tutorials, however, here are some examples and walk throughs of the platform.\n",
    "- [Example 0: The basics of the ML platform](/platform/example-0-platform.ipynb)\n",
    "- [Example 1: Working with data](/platform/example-1-data.ipynb)\n",
    "\n",
    "### Experiments\n",
    "Experiments that we have run that are relevant to our thesis are made available in the experiments folder. For each experiment we have a notebook that describes the experiment and a configuration file that can be used to run the experiment. \n",
    "\n",
    "### Some known issues\n",
    "- Running multiple instances of the platform may not work as expected due to ray as backend for federated and swarm learning.\n",
    "- For federated and swarm learning, ray leaves idle workers with high GPU Memory usage. This may cause CUDA out of memory (OOM) errors. This can partially be solved by minimising the number of available processes/workers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The configuration object\n",
    "The configuration object is a dictionary that contains all the parameters needed to build and train a model. The configuration object is passed to the platform when creating a dataset, a model, or when training a model. The configuration object is also stored so that it can be used to reproduce the results.\n",
    "\n",
    "Let's take a look at the `config`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"data\":{\n",
    "        \"path\": \"/mnt/ZOD\",\n",
    "        \"version\":\"full\",\n",
    "        \"ratio\":0.003,\n",
    "        \"shuffle_seed\": 42,\n",
    "        \"img_size\": 160,\n",
    "        \"transforms\":\"[Resize((img_size, img_size))]\",\n",
    "        \"dataloader_args\": {\n",
    "            \"prefetch_factor\": 2,\n",
    "            \"num_workers\": 2,\n",
    "            \"batch_size\": 32,\n",
    "        }\n",
    "    },\n",
    "    \"model\":{\n",
    "        \"name\": \"default\",\n",
    "        \"args\": {\n",
    "            \"num_output\":66\n",
    "        },\n",
    "        \"loss\":\"MSELoss\"\n",
    "    },\n",
    "    \"central\":{\n",
    "        \"train\":\"false\",\n",
    "        \"use_gpu\":\"true\",\n",
    "        \"epochs\": 10\n",
    "    },\n",
    "    \"decentralised\":{\n",
    "        \"train\": [\"federated\", \"swarm\", \"baseline\"],\n",
    "        \"global\":{\n",
    "            \"n_clients\":5,\n",
    "            \"global_rounds\":3,\n",
    "            \"client_resources\":{\n",
    "                \"num_cpus\": 2, \n",
    "                \"num_gpus\": 0.2\n",
    "            },\n",
    "            \"ray_init_args\":{\n",
    "                \"include_dashboard\": True,\n",
    "                \"num_cpus\": 12,\n",
    "                \"num_gpus\": 2\n",
    "            },\n",
    "            \"swarm_orchestrator\": \"synchronous_fixed_rounds_fc\",\n",
    "        },\n",
    "        \"client\": {\n",
    "            \"epochs\": 3\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the `config` object. The `config` object is a dictionary that contains all the parameters needed to build and train a model. The `config` object is passed to the platform when creating a dataset, a model, or when training a model. The `config` object is also stored so that it can be used to reproduce the results.\n",
    "\n",
    "Not all parameters are required. The above example configuration is one of the minimal examples where we use the same global and client configuration for our decentralised methods and limited to no custom methods. For more information about the schema of the configuration object, please see the [configuration schema](utils/templates/config_schema.json)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's run the platform with the configuration object. The above configuration will create our required datasets and models, and train them. When you create an instance of the platform, a `run` is initalised. A `run` is stored under the `runs` folder and is named after the timestamp of when the platform was initalised (2023-03-14_15:02:49). The results and pending progress is logged to tensorboard files that are stored in this folder and all log files are also stored in this `run` folder.\n",
    "\n",
    "To begin, we will start a tensorboard session to monitor the training progress. To do this, run the following command in a terminal:\n",
    "\n",
    "```bash\n",
    "tensorboard --logdir runs\n",
    "```\n",
    "\n",
    "This will start a web server that will allow you to monitor the training progress. You can access the web server by going to [http://localhost:6006](http://localhost:6006) (Or other port if specified)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fedswarm import Platform\n",
    "\n",
    "platform = Platform(config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optional parameters\n",
    "If required, it is possible to specify different client and global configurations for the different decentralised methods. While the summary notation allows you to define a `global` and `client` config for all decentralised tasks. It is indeed possible to have one unique for each.\n",
    "\n",
    "The config parser reads the `decentralised` configuration and expands it, this means that the config feed to the platform is actually a config where each decentralised task has its own `global` and `client` configuration. This is done to simplify the configuration of the platform. The expanded config is saved to tensorboard. However, this means that we can also specify our own `global` and `client` configuration for each decentralised task. This is done by specifying the `global` and `client` configuration for each task. \n",
    "\n",
    "For example, if we want to use a different `global` configuration for swarm learning but the same for federated and baseline, then we can use the following sub-config:\n",
    "\n",
    "```json\n",
    "    \"decentralised\":{\n",
    "        \"train\": [\"federated\", \"baseline\"],\n",
    "        \"global\":{\n",
    "            \"n_clients\":5,\n",
    "            \"global_rounds\":3,\n",
    "            \"client_resources\":{\n",
    "                \"num_cpus\": 2, \n",
    "                \"num_gpus\": 0.2\n",
    "            },\n",
    "            \"ray_init_args\":{\n",
    "                \"include_dashboard\": True,\n",
    "                \"num_cpus\": 12,\n",
    "                \"num_gpus\": 2\n",
    "            },\n",
    "            \"swarm_orchestrator\": \"synchronous_fixed_rounds_fc\",\n",
    "        },\n",
    "        \"client\": {\n",
    "            \"epochs\": 3\n",
    "        }\n",
    "    },\n",
    "    \"swarm\":{\n",
    "        \"train\": \"true\",\n",
    "        \"global\":{\n",
    "            \"n_clients\":5,\n",
    "            \"global_rounds\":3,\n",
    "            \"client_resources\":{\n",
    "                \"num_cpus\": 2, \n",
    "                \"num_gpus\": 0.2\n",
    "            },\n",
    "            \"ray_init_args\":{\n",
    "                \"include_dashboard\": True,\n",
    "                \"num_cpus\": 12,\n",
    "                \"num_gpus\": 2\n",
    "            },\n",
    "            \"orchestrator\": \"synchronous_fixed_rounds_fc\",\n",
    "        },\n",
    "        \"client\": {\n",
    "            \"epochs\": 3\n",
    "        }\n",
    "    }\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be done in the same manner for all decentralised methods. This allows for a lot of flexibility in the configuration of the platform. Note that method specific configurations should include the `\"train\"` key and it should be set to `\"true\"` to enable it."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shorthand notation\n",
    "For easier configuration, the platform supports a shorthand notation. This shorthand notation allows you to define method specific global arguments without doing method specific configurations. For instance, in the example above, note how we have included `swarm_orchestrator` in the `global` configuration. This is a shorthand notation and the config parser will add `orchestrator`and its value to the `swarm` config under the `global` parameter. \n",
    "\n",
    "To add more method specific parameters, ensure that the parameter in the summary notation begins with the method name and is followed by `\"_\"`. This is how the parser identifies which method the parameter belongs to."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Argument parameters\n",
    "There are several argument parameters in the config. The dictionary provided in the config will be passed to the function that uses it as keyword arguments. Thus, it is important to ensure that the keys in the dictionary are the same as the keyword arguments of the function.\n",
    "\n",
    "- `dataloader_args`: Arguments to be passed to the dataloader.\n",
    "- `model_args`: Arguments to be passed to the model.\n",
    "- `ray_init_args`: Arguments to be passed to the ray init function.\n",
    "- `client_resources`: Resources to be passed to the ray client.\n",
    "\n",
    "For requirements on the arguments, please see the documentation of the functions that use them.\n",
    "\n",
    "### Function parameters\n",
    "There are several parameters that define which functions to use, for instance:\n",
    "- `model`: The model to use.\n",
    "- `loss`: The loss function to use.\n",
    "- `orchestrator`: The orchestrator to use for swarm learning.\n",
    "- `train_val_id_generator`: The function to use to generate the train, validation and test ids.\n",
    "- `transorms`: The transforms to use for the dataset.\n",
    "\n",
    "For many of these such as `loss` it is important to ensure that the function is written as how it would be written in code. For instance, if you want to use MSE Loss, then you should write `MSELoss` as in `torch.nn.MSELoss`. This is because the platform will use `eval` to evaluate the string to a function. The same general concept applies to most of the function parameters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "swarm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
